{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/cse587/spark-2.4.0-bin-hadoop2.7')\n",
    "import pyspark\n",
    "sc=pyspark.SparkContext()\n",
    "from pyspark.sql import *\n",
    "sqlContext = SQLContext(sc)\n",
    "from pyspark.sql.functions import udf,col,concat_ws\n",
    "spark=SparkSession.builder.appName(\"Pyspark Demo\").config(\"sparl.some.config.option\",\"some-value\").getOrCreate()\n",
    "import re\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import monotonically_increasing_id \n",
    "from pyspark.sql.functions import udf, col, lower, regexp_replace\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, RegexTokenizer\n",
    "from pyspark.sql.functions import trim\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.mllib.evaluation import MultilabelMetrics\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import IntegerType\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.types import DoubleType\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: long (nullable = true)\n",
      " |-- movie_name: string (nullable = true)\n",
      " |-- plot: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pd_train_data= pd.read_csv(\"train.csv\")\n",
    "train_data=spark.createDataFrame(pd_train_data,schema=None,verifySchema=True)\n",
    "train_data.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: long (nullable = true)\n",
      " |-- movie_name: string (nullable = true)\n",
      " |-- plot: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pd_test_data= pd.read_csv(\"test.csv\")\n",
    "test_data=spark.createDataFrame(pd_test_data,schema=None,verifySchema=True)\n",
    "test_data.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Unnamed: 0: long (nullable = true)\n",
      " |-- 0: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pd_mapping = pd.read_csv(\"mapping.csv\")\n",
    "mapping=spark.createDataFrame(pd_mapping)\n",
    "mapping.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "maplist = [row for row in mapping.select('0').collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(map_list=[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_list(x):\n",
    "    z=x.collect()\n",
    "    map_data=[]\n",
    "    for j in range(0,x.count()):\n",
    "        res=[]\n",
    "        genre_list=z[j][0].replace('[','').replace(']','').replace(\"'\",\"\").split(',')\n",
    "        genre=[]\n",
    "        for g in genre_list:\n",
    "            genre.append(g.strip())\n",
    "        for k in enumerate(maplist):\n",
    "            if k[1][0] in genre:\n",
    "                res.append(1)\n",
    "            else:\n",
    "                res.append(0)\n",
    "#         listToStr = ' '.join([str(elem) for elem in res]) \n",
    "        map_data.append(res)\n",
    "    rdd1 = sc.parallelize(map_data)\n",
    "    row_rdd = rdd1.map(lambda x: Row(x))\n",
    "    return sqlContext.createDataFrame(row_rdd,['map_list'])\n",
    "map_data = map_list(train_data.select('genre'))\n",
    "map_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+--------------------+--------------------+--------------------+--------------------+\n",
      "|index|movie_id|          movie_name|                plot|               genre|            map_list|\n",
      "+-----+--------+--------------------+--------------------+--------------------+--------------------+\n",
      "|   26|18549958|          Love, Mary|Mary was a lonely...|           ['Drama']|[1, 0, 0, 0, 0, 0...|\n",
      "|   29| 3150865| Yankee Doodle Daffy|Porky Pig is tryi...|['Animation', 'Co...|[0, 1, 0, 0, 0, 0...|\n",
      "|  474| 4345210|     Learning to Lie|Beginning in West...|    ['Romance Film']|[0, 0, 1, 0, 0, 0...|\n",
      "|  964|14072881|   Boys' Reformatory|Seventeen-year-ol...|['Black-and-white...|[1, 0, 0, 0, 0, 0...|\n",
      "| 1677| 4711636|The Last Flight o...|A jaded pilot nam...|       ['Adventure']|[0, 0, 0, 0, 0, 0...|\n",
      "| 1697|27181651|              Esther|Hadassah , a beau...|['Drama', 'Crime ...|[1, 0, 1, 0, 0, 0...|\n",
      "| 1806|26551541|      Triple Trouble|The boys are on t...|['Crime Fiction',...|[0, 1, 0, 0, 1, 0...|\n",
      "| 1950|24070825|         Summer Rain|The film takes pl...|['Romance Film', ...|[1, 0, 1, 0, 0, 1...|\n",
      "| 2040|30897463|         Makaramanju|The film tells th...|    ['Romance Film']|[0, 0, 1, 0, 0, 0...|\n",
      "| 2214| 5349196|                Arul|Arul ([[Vikram , ...|['Musical', 'Worl...|[1, 0, 0, 0, 0, 1...|\n",
      "| 2250|32751781|      Bush Christmas|In the Australian...|['Adventure', 'Fa...|[1, 0, 0, 0, 0, 0...|\n",
      "| 2453|28733517|   A Town Like Alice|In Post-WW2 Londo...|['Drama', 'Romanc...|[1, 0, 1, 0, 0, 0...|\n",
      "| 2509|11453926|  Getting Acquainted|Charlie and his w...|['Black-and-white...|[0, 1, 0, 0, 0, 0...|\n",
      "| 2529|16190026|Unstable Fables: ...|July 2012}} Goldi...|['Animation', 'Fa...|[0, 0, 0, 0, 0, 0...|\n",
      "| 2927|11517297|The Law of the Range|Betty Dallas is a...|           ['Indie']|[0, 0, 0, 0, 0, 0...|\n",
      "| 3091| 3492883|  Kronk's New Groove|Emperor Kuzco  na...|['Animation', 'Fa...|[0, 0, 0, 0, 0, 0...|\n",
      "| 3506| 2257809|          Judas Kiss|Coco Chavez  and ...|['Crime Fiction',...|[1, 0, 0, 1, 0, 0...|\n",
      "| 3764|20318100|  Breaking the Rules|Phil , reunites w...|           ['Drama']|[1, 0, 0, 0, 0, 0...|\n",
      "| 4590| 2918524|      Secret Admirer|Michael Ryan  is ...|['Indie', 'Comedy...|[0, 1, 1, 0, 0, 0...|\n",
      "| 4823|13607881|      The Barbarians|The film is set i...|['Adventure', 'Ac...|[0, 0, 0, 0, 1, 0...|\n",
      "+-----+--------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data_new = train_data.withColumn(\"index\", monotonically_increasing_id())\n",
    "map_data_new = map_data.withColumn(\"index\", monotonically_increasing_id())\n",
    "\n",
    "train_data = train_data_new.join(map_data_new, on=['index'], how='inner')\n",
    "\n",
    "train_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_plot(data,mode):\n",
    "    # Convert text to lower case\n",
    "    data = data.withColumn('plot', (lower(col('plot')).alias('plot')))\n",
    "\n",
    "    # Tokenize text\n",
    "    tokenizer = RegexTokenizer(inputCol='plot', outputCol='plot_token',pattern=\"\\\\W\")\n",
    "    data = tokenizer.transform(data)\n",
    "\n",
    "\n",
    "    # Remove stop words\n",
    "    stopwords = StopWordsRemover(inputCol='plot_token', outputCol='plot_stop')\n",
    "    data = stopwords.transform(data)\n",
    "\n",
    "    # Remove blank strings from plot tokens\n",
    "    data=data.withColumn(\"plot_stop\", concat_ws(\",\", \"plot_stop\"))\n",
    "    data = data.withColumn('plot_stop', regexp_replace('plot_stop', ',', ' '))\n",
    "    data = data.withColumn(\"plot_stop\", trim(regexp_replace('plot_stop', \" +\", \" \")))\n",
    "    tokenizer = RegexTokenizer(inputCol='plot_stop', outputCol='plot_output',pattern=\"\\\\W\")\n",
    "    data = tokenizer.transform(data)\n",
    "    if (mode=='train'):\n",
    "        data = data.select('movie_id','plot_output','map_list')\n",
    "    if (mode=='test'):\n",
    "        data = data.select('movie_id','plot_output')\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+\n",
      "|movie_id|         plot_output|            map_list|\n",
      "+--------+--------------------+--------------------+\n",
      "|18549958|[mary, lonely, po...|[1, 0, 0, 0, 0, 0...|\n",
      "| 3150865|[porky, pig, tryi...|[0, 1, 0, 0, 0, 0...|\n",
      "| 4345210|[beginning, west,...|[0, 0, 1, 0, 0, 0...|\n",
      "|14072881|[seventeen, year,...|[1, 0, 0, 0, 0, 0...|\n",
      "| 4711636|[jaded, pilot, na...|[0, 0, 0, 0, 0, 0...|\n",
      "|27181651|[hadassah, beauti...|[1, 0, 1, 0, 0, 0...|\n",
      "|26551541|[boys, way, home,...|[0, 1, 0, 0, 1, 0...|\n",
      "|24070825|[film, takes, pla...|[1, 0, 1, 0, 0, 1...|\n",
      "|30897463|[film, tells, sto...|[0, 0, 1, 0, 0, 0...|\n",
      "| 5349196|[arul, vikram, wo...|[1, 0, 0, 0, 0, 1...|\n",
      "|32751781|[australian, coun...|[1, 0, 0, 0, 0, 0...|\n",
      "|28733517|[post, ww2, londo...|[1, 0, 1, 0, 0, 0...|\n",
      "|11453926|[charlie, wife, w...|[0, 1, 0, 0, 0, 0...|\n",
      "|16190026|[july, 2012, gold...|[0, 0, 0, 0, 0, 0...|\n",
      "|11517297|[betty, dallas, p...|[0, 0, 0, 0, 0, 0...|\n",
      "| 3492883|[emperor, kuzco, ...|[0, 0, 0, 0, 0, 0...|\n",
      "| 2257809|[coco, chavez, ju...|[1, 0, 0, 1, 0, 0...|\n",
      "|20318100|[phil, reunites, ...|[1, 0, 0, 0, 0, 0...|\n",
      "| 2918524|[michael, ryan, h...|[0, 1, 1, 0, 0, 0...|\n",
      "|13607881|[film, set, medie...|[0, 0, 0, 0, 1, 0...|\n",
      "+--------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data=process_plot(train_data,'train')\n",
    "train_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|movie_id|         plot_output|\n",
      "+--------+--------------------+\n",
      "| 1335380|[film, based, eve...|\n",
      "|29062594|[group, teenagers...|\n",
      "| 9252321|[story, zulu, fam...|\n",
      "|13455076|[stooges, play, t...|\n",
      "|24165951|[soldier, fortune...|\n",
      "| 1925869|[set, northwester...|\n",
      "|10799612|[like, many, moni...|\n",
      "|28238240|[mickey, scorpion...|\n",
      "|17124781|[desert, wilderne...|\n",
      "|28207941|[bimbo, koko, sig...|\n",
      "|19174305|[tahaan, lives, g...|\n",
      "|18392317|[betty, startled,...|\n",
      "|34420857|[nirmal, karthik,...|\n",
      "| 4039635|[group, journalis...|\n",
      "| 8034072|[vaibhavari, saha...|\n",
      "| 4016437|[1947, movie, nar...|\n",
      "| 1520023|[ninja, resurrect...|\n",
      "|24589422|[spring, 1946, iv...|\n",
      "|35068740|[muthu, prabhu, v...|\n",
      "|21132951|[vishwanathan, in...|\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data=process_plot(test_data,'test')\n",
    "test_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Document Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+--------------------+\n",
      "|movie_id|         plot_output|            map_list|            features|\n",
      "+--------+--------------------+--------------------+--------------------+\n",
      "|18549958|[mary, lonely, po...|[1, 0, 0, 0, 0, 0...|(500,[1,14,21,48,...|\n",
      "| 3150865|[porky, pig, tryi...|[0, 1, 0, 0, 0, 0...|(500,[1,11,15,17,...|\n",
      "| 4345210|[beginning, west,...|[0, 0, 1, 0, 0, 0...|(500,[0,3,6,7,9,1...|\n",
      "|14072881|[seventeen, year,...|[1, 0, 0, 0, 0, 0...|(500,[0,5,8,11,12...|\n",
      "| 4711636|[jaded, pilot, na...|[0, 0, 0, 0, 0, 0...|(500,[1,2,4,8,10,...|\n",
      "|27181651|[hadassah, beauti...|[1, 0, 1, 0, 0, 0...|(500,[0,1,2,5,6,7...|\n",
      "|26551541|[boys, way, home,...|[0, 1, 0, 0, 1, 0...|(500,[6,7,12,15,2...|\n",
      "|24070825|[film, takes, pla...|[1, 0, 1, 0, 0, 1...|(500,[0,2,4,5,7,8...|\n",
      "|30897463|[film, tells, sto...|[0, 0, 1, 0, 0, 0...|(500,[4,6,8,10,11...|\n",
      "| 5349196|[arul, vikram, wo...|[1, 0, 0, 0, 0, 1...|(500,[0,3,10,13,1...|\n",
      "|32751781|[australian, coun...|[1, 0, 0, 0, 0, 0...|(500,[0,3,7,11,23...|\n",
      "|28733517|[post, ww2, londo...|[1, 0, 1, 0, 0, 0...|(500,[0,1,4,6,7,8...|\n",
      "|11453926|[charlie, wife, w...|[0, 1, 0, 0, 0, 0...|(500,[28,88,98,23...|\n",
      "|16190026|[july, 2012, gold...|[0, 0, 0, 0, 0, 0...|(500,[4,14,36,41,...|\n",
      "|11517297|[betty, dallas, p...|[0, 0, 0, 0, 0, 0...|(500,[0,2,50,52,6...|\n",
      "| 3492883|[emperor, kuzco, ...|[0, 0, 0, 0, 0, 0...|(500,[0,1,2,3,4,6...|\n",
      "| 2257809|[coco, chavez, ju...|[1, 0, 0, 1, 0, 0...|(500,[0,2,7,9,11,...|\n",
      "|20318100|[phil, reunites, ...|[1, 0, 0, 0, 0, 0...|(500,[2,6,21,31,4...|\n",
      "| 2918524|[michael, ryan, h...|[0, 1, 1, 0, 0, 0...|(500,[2,3,6,10,12...|\n",
      "|13607881|[film, set, medie...|[0, 0, 0, 0, 1, 0...|(500,[1,2,4,8,15,...|\n",
      "+--------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(inputCol=\"plot_output\", outputCol=\"features\",vocabSize=500, minDF=20)\n",
    "basic_model = cv.fit(train_data)\n",
    "train_data_basic = basic_model.transform(train_data)\n",
    "train_data_basic.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+\n",
      "|movie_id|         plot_output|            features|\n",
      "+--------+--------------------+--------------------+\n",
      "| 1335380|[film, based, eve...|(500,[0,3,6,7,8,9...|\n",
      "|29062594|[group, teenagers...|(500,[7,12,56,67,...|\n",
      "| 9252321|[story, zulu, fam...|(500,[4,7,8,10,13...|\n",
      "|13455076|[stooges, play, t...|(500,[0,76,78,79,...|\n",
      "|24165951|[soldier, fortune...|(500,[19,392,439]...|\n",
      "| 1925869|[set, northwester...|(500,[0,1,2,3,4,5...|\n",
      "|10799612|[like, many, moni...|(500,[0,5,6,9,12,...|\n",
      "|28238240|[mickey, scorpion...|(500,[13,21,191,2...|\n",
      "|17124781|[desert, wilderne...|(500,[4,8,11,13,1...|\n",
      "|28207941|[bimbo, koko, sig...|(500,[55,56,222,3...|\n",
      "|19174305|[tahaan, lives, g...|(500,[1,3,4,7,8,1...|\n",
      "|18392317|[betty, startled,...|(500,[6,7,16,20,2...|\n",
      "|34420857|[nirmal, karthik,...|(500,[3,5,8,9,17,...|\n",
      "| 4039635|[group, journalis...|(500,[0,1,6,16,26...|\n",
      "| 8034072|[vaibhavari, saha...|(500,[2,3,9,10,12...|\n",
      "| 4016437|[1947, movie, nar...|(500,[0,2,3,5,9,1...|\n",
      "| 1520023|[ninja, resurrect...|(500,[0,1,2,3,4,5...|\n",
      "|24589422|[spring, 1946, iv...|(500,[0,1,3,5,7,8...|\n",
      "|35068740|[muthu, prabhu, v...|(500,[9,18,26,34,...|\n",
      "|21132951|[vishwanathan, in...|(500,[0,3,4,9,10,...|\n",
      "+--------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(inputCol=\"plot_output\", outputCol=\"features\",vocabSize=500, minDF=20)\n",
    "basic_model_test = cv.fit(test_data)\n",
    "test_data_basic = basic_model_test.transform(test_data)\n",
    "test_data_basic.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlist = train_data_basic.columns\n",
    "train_data_basic=train_data_basic.select(dlist+[(col(\"map_list\")[x]).alias(\"genre\"+str(x+1)) for x in range(0, 20)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (trainset_basic, valset_basic) = train_data_basic.randomSplit([0.8, 0.2], seed = 121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "pred_list=[]\n",
    "for i in range(1,21):\n",
    "    \n",
    "    lr = LogisticRegression(featuresCol = 'features', labelCol='genre%s'%i,maxIter=5)\n",
    "    lrModel = lr.fit(train_data_basic)\n",
    "    predictions_test = lrModel.transform(test_data_basic)\n",
    "    predictions_test = predictions_test.withColumn(\"prediction\", predictions_test[\"prediction\"].cast(IntegerType()))\n",
    "    predictions_test = (predictions_test.withColumnRenamed('prediction','prediction%s'%i))\n",
    "    pred_list.append(predictions_test.select('prediction%s'%i).withColumn(\"index\", monotonically_increasing_id()))\n",
    "    print(i)\n",
    "movie_list=predictions_test.select('movie_id').withColumn(\"index\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df=reduce(lambda x,y:x.join(y,['index'],how='full'),[pl.selectExpr('index',f'prediction{i+1}') for i, pl in enumerate(pred_list)])\n",
    "pred_df =pred_df.withColumn('predictions',concat_ws(\" \",*['prediction%d' %i for i in range(1,len(pred_list)+1)])).select('predictions','index')\n",
    "outputfile = pred_df.join(movie_list, on=['index'], how='inner')\n",
    "outputfile.select('movie_id','predictions').toPandas().to_csv('outputpart1.csv',index=False,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+--------------------+--------------------+\n",
      "|movie_id|         plot_output|            map_list|         rawFeatures|            features|\n",
      "+--------+--------------------+--------------------+--------------------+--------------------+\n",
      "|18549958|[mary, lonely, po...|[1, 0, 0, 0, 0, 0...|(262144,[14699,16...|(262144,[14699,16...|\n",
      "| 3150865|[porky, pig, tryi...|[0, 1, 0, 0, 0, 0...|(262144,[9129,120...|(262144,[9129,120...|\n",
      "| 4345210|[beginning, west,...|[0, 0, 1, 0, 0, 0...|(262144,[3834,420...|(262144,[3834,420...|\n",
      "|14072881|[seventeen, year,...|[1, 0, 0, 0, 0, 0...|(262144,[1133,183...|(262144,[1133,183...|\n",
      "| 4711636|[jaded, pilot, na...|[0, 0, 0, 0, 0, 0...|(262144,[571,2089...|(262144,[571,2089...|\n",
      "|27181651|[hadassah, beauti...|[1, 0, 1, 0, 0, 0...|(262144,[329,1998...|(262144,[329,1998...|\n",
      "|26551541|[boys, way, home,...|[0, 1, 0, 0, 1, 0...|(262144,[9706,138...|(262144,[9706,138...|\n",
      "|24070825|[film, takes, pla...|[1, 0, 1, 0, 0, 1...|(262144,[7367,102...|(262144,[7367,102...|\n",
      "|30897463|[film, tells, sto...|[0, 0, 1, 0, 0, 0...|(262144,[6446,859...|(262144,[6446,859...|\n",
      "| 5349196|[arul, vikram, wo...|[1, 0, 0, 0, 0, 1...|(262144,[3924,493...|(262144,[3924,493...|\n",
      "|32751781|[australian, coun...|[1, 0, 0, 0, 0, 0...|(262144,[4200,608...|(262144,[4200,608...|\n",
      "|28733517|[post, ww2, londo...|[1, 0, 1, 0, 0, 0...|(262144,[3924,409...|(262144,[3924,409...|\n",
      "|11453926|[charlie, wife, w...|[0, 1, 0, 0, 0, 0...|(262144,[23629,65...|(262144,[23629,65...|\n",
      "|16190026|[july, 2012, gold...|[0, 0, 0, 0, 0, 0...|(262144,[571,2270...|(262144,[571,2270...|\n",
      "|11517297|[betty, dallas, p...|[0, 0, 0, 0, 0, 0...|(262144,[15664,35...|(262144,[15664,35...|\n",
      "| 3492883|[emperor, kuzco, ...|[0, 0, 0, 0, 0, 0...|(262144,[3782,410...|(262144,[3782,410...|\n",
      "| 2257809|[coco, chavez, ju...|[1, 0, 0, 1, 0, 0...|(262144,[8985,912...|(262144,[8985,912...|\n",
      "|20318100|[phil, reunites, ...|[1, 0, 0, 0, 0, 0...|(262144,[15664,20...|(262144,[15664,20...|\n",
      "| 2918524|[michael, ryan, h...|[0, 1, 1, 0, 0, 0...|(262144,[571,6286...|(262144,[571,6286...|\n",
      "|13607881|[film, set, medie...|[0, 0, 0, 0, 1, 0...|(262144,[2325,271...|(262144,[2325,271...|\n",
      "+--------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"plot_output\", outputCol=\"rawFeatures\")\n",
    "train_data_tf = hashingTF.transform(train_data)\n",
    "# alternatively, CountVectorizer can also be used to get term frequency vectors\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\",minDocFreq=100)\n",
    "idfModel = idf.fit(train_data_tf)\n",
    "train_data_tf = idfModel.transform(train_data_tf)\n",
    "\n",
    "train_data_tf.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+--------------------+\n",
      "|movie_id|         plot_output|         rawFeatures|            features|\n",
      "+--------+--------------------+--------------------+--------------------+\n",
      "| 1335380|[film, based, eve...|(262144,[1728,261...|(262144,[1728,261...|\n",
      "|29062594|[group, teenagers...|(262144,[6068,191...|(262144,[6068,191...|\n",
      "| 9252321|[story, zulu, fam...|(262144,[1598,208...|(262144,[1598,208...|\n",
      "|13455076|[stooges, play, t...|(262144,[3294,618...|(262144,[3294,618...|\n",
      "|24165951|[soldier, fortune...|(262144,[4098,644...|(262144,[4098,644...|\n",
      "| 1925869|[set, northwester...|(262144,[535,3294...|(262144,[535,3294...|\n",
      "|10799612|[like, many, moni...|(262144,[5053,538...|(262144,[5053,538...|\n",
      "|28238240|[mickey, scorpion...|(262144,[23060,30...|(262144,[23060,30...|\n",
      "|17124781|[desert, wilderne...|(262144,[5232,733...|(262144,[5232,733...|\n",
      "|28207941|[bimbo, koko, sig...|(262144,[9726,626...|(262144,[9726,626...|\n",
      "|19174305|[tahaan, lives, g...|(262144,[2710,392...|(262144,[2710,392...|\n",
      "|18392317|[betty, startled,...|(262144,[5213,606...|(262144,[5213,606...|\n",
      "|34420857|[nirmal, karthik,...|(262144,[11275,13...|(262144,[11275,13...|\n",
      "| 4039635|[group, journalis...|(262144,[571,1640...|(262144,[571,1640...|\n",
      "| 8034072|[vaibhavari, saha...|(262144,[991,4200...|(262144,[991,4200...|\n",
      "| 4016437|[1947, movie, nar...|(262144,[5595,783...|(262144,[5595,783...|\n",
      "| 1520023|[ninja, resurrect...|(262144,[14,535,5...|(262144,[14,535,5...|\n",
      "|24589422|[spring, 1946, iv...|(262144,[1998,249...|(262144,[1998,249...|\n",
      "|35068740|[muthu, prabhu, v...|(262144,[2710,484...|(262144,[2710,484...|\n",
      "|21132951|[vishwanathan, in...|(262144,[1841,392...|(262144,[1841,392...|\n",
      "+--------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hashingTF = HashingTF(inputCol=\"plot_output\", outputCol=\"rawFeatures\")\n",
    "test_data_tf = hashingTF.transform(test_data)\n",
    "# alternatively, CountVectorizer can also be used to get term frequency vectors\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\",minDocFreq=100)\n",
    "idfModel = idf.fit(test_data_tf)\n",
    "test_data_tf = idfModel.transform(test_data_tf)\n",
    "\n",
    "test_data_tf.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlist = train_data_tf.columns\n",
    "train_data_tf=train_data_tf.select(dlist+[(col(\"map_list\")[x]).alias(\"genre\"+str(x+1)) for x in range(0, 20)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (trainset_tfidf, valset_tfidf) = train_data_tf.randomSplit([0.8, 0.2], seed = 121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "pred_list=[]\n",
    "for i in range(1,21):\n",
    "    \n",
    "    lr = LogisticRegression(featuresCol = 'features', labelCol='genre%s'%i,maxIter=5)\n",
    "    lrModel = lr.fit(train_data_tf)\n",
    "    \n",
    "    predictions_test = lrModel.transform(test_data_tf)\n",
    "    predictions_test = predictions_test.withColumn(\"prediction\", predictions_test[\"prediction\"].cast(IntegerType()))\n",
    "    predictions_test = (predictions_test.withColumnRenamed('prediction','prediction%s'%i))\n",
    "    pred_list.append(predictions_test.select('prediction%s'%i).withColumn(\"index\", monotonically_increasing_id()))\n",
    "    print(i)\n",
    "movie_list=predictions_test.select('movie_id').withColumn(\"index\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df=reduce(lambda x,y:x.join(y,['index'],how='full'),[pl.selectExpr('index',f'prediction{i+1}') for i, pl in enumerate(pred_list)])\n",
    "pred_df =pred_df.withColumn('predictions',concat_ws(\" \",*['prediction%d' %i for i in range(1,len(pred_list)+1)])).select('predictions','index')\n",
    "outputfile = pred_df.join(movie_list, on=['index'], how='inner')\n",
    "outputfile.select('movie_id','predictions').toPandas().to_csv('outputpart2.csv',index=False,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+--------------------+\n",
      "|movie_id|         plot_output|            map_list|            features|\n",
      "+--------+--------------------+--------------------+--------------------+\n",
      "|18549958|[mary, lonely, po...|[1, 0, 0, 0, 0, 0...|[0.08346132726364...|\n",
      "| 3150865|[porky, pig, tryi...|[0, 1, 0, 0, 0, 0...|[-0.0229134946882...|\n",
      "| 4345210|[beginning, west,...|[0, 0, 1, 0, 0, 0...|[0.12968615381396...|\n",
      "|14072881|[seventeen, year,...|[1, 0, 0, 0, 0, 0...|[0.03247320896284...|\n",
      "| 4711636|[jaded, pilot, na...|[0, 0, 0, 0, 0, 0...|[0.03273211191200...|\n",
      "|27181651|[hadassah, beauti...|[1, 0, 1, 0, 0, 0...|[0.06491560155602...|\n",
      "|26551541|[boys, way, home,...|[0, 1, 0, 0, 1, 0...|[-0.0139750445984...|\n",
      "|24070825|[film, takes, pla...|[1, 0, 1, 0, 0, 1...|[0.09414260529068...|\n",
      "|30897463|[film, tells, sto...|[0, 0, 1, 0, 0, 0...|[0.09715022520641...|\n",
      "| 5349196|[arul, vikram, wo...|[1, 0, 0, 0, 0, 1...|[0.03366250111255...|\n",
      "|32751781|[australian, coun...|[1, 0, 0, 0, 0, 0...|[0.03667745156697...|\n",
      "|28733517|[post, ww2, londo...|[1, 0, 1, 0, 0, 0...|[0.06562598947156...|\n",
      "|11453926|[charlie, wife, w...|[0, 1, 0, 0, 0, 0...|[0.14203530089820...|\n",
      "|16190026|[july, 2012, gold...|[0, 0, 0, 0, 0, 0...|[0.01481960669379...|\n",
      "|11517297|[betty, dallas, p...|[0, 0, 0, 0, 0, 0...|[-0.0395978756994...|\n",
      "| 3492883|[emperor, kuzco, ...|[0, 0, 0, 0, 0, 0...|[0.03002840106451...|\n",
      "| 2257809|[coco, chavez, ju...|[1, 0, 0, 1, 0, 0...|[0.01158235209935...|\n",
      "|20318100|[phil, reunites, ...|[1, 0, 0, 0, 0, 0...|[0.02796784439124...|\n",
      "| 2918524|[michael, ryan, h...|[0, 1, 1, 0, 0, 0...|[0.09170610800632...|\n",
      "|13607881|[film, set, medie...|[0, 0, 0, 0, 1, 0...|[0.04268197335028...|\n",
      "+--------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Word2Vec\n",
    "\n",
    "word2Vec = Word2Vec(vectorSize=200, minCount=5, inputCol=\"plot_output\", outputCol=\"features\")\n",
    "model = word2Vec.fit(train_data)\n",
    "\n",
    "train_data_wv = model.transform(train_data)\n",
    "train_data_wv.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+\n",
      "|movie_id|         plot_output|            features|\n",
      "+--------+--------------------+--------------------+\n",
      "| 1335380|[film, based, eve...|[0.05598512597684...|\n",
      "|29062594|[group, teenagers...|[0.14241938944905...|\n",
      "| 9252321|[story, zulu, fam...|[0.07958495482291...|\n",
      "|13455076|[stooges, play, t...|[0.07475852966925...|\n",
      "|24165951|[soldier, fortune...|[-0.0557895397651...|\n",
      "| 1925869|[set, northwester...|[0.02304582834951...|\n",
      "|10799612|[like, many, moni...|[0.08219743698370...|\n",
      "|28238240|[mickey, scorpion...|[0.01957262284122...|\n",
      "|17124781|[desert, wilderne...|[0.00473414125503...|\n",
      "|28207941|[bimbo, koko, sig...|[0.05876081616484...|\n",
      "|19174305|[tahaan, lives, g...|[0.04216506349735...|\n",
      "|18392317|[betty, startled,...|[0.04898787961876...|\n",
      "|34420857|[nirmal, karthik,...|[0.03164040526873...|\n",
      "| 4039635|[group, journalis...|[0.05018935955401...|\n",
      "| 8034072|[vaibhavari, saha...|[0.06937972646987...|\n",
      "| 4016437|[1947, movie, nar...|[0.08186267208740...|\n",
      "| 1520023|[ninja, resurrect...|[0.02908442305884...|\n",
      "|24589422|[spring, 1946, iv...|[0.07842324633508...|\n",
      "|35068740|[muthu, prabhu, v...|[0.02678842949377...|\n",
      "|21132951|[vishwanathan, in...|[0.02640920569909...|\n",
      "+--------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word2Vec = Word2Vec(vectorSize=200, minCount=5, inputCol=\"plot_output\", outputCol=\"features\")\n",
    "model_test = word2Vec.fit(test_data)\n",
    "\n",
    "test_data_wv = model.transform(test_data)\n",
    "test_data_wv.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlist = train_data_wv.columns\n",
    "train_data_wv=train_data_wv.select(dlist+[(col(\"map_list\")[x]).alias(\"genre\"+str(x+1)) for x in range(0, 20)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (trainset_wv, valset_wv) = train_data_wv.randomSplit([0.8, 0.2], seed = 121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "pred_list=[]\n",
    "for i in range(1,21):\n",
    "    \n",
    "    lr = LogisticRegression(featuresCol = 'features', labelCol='genre%s'%i,maxIter=5)\n",
    "    lrModel = lr.fit(trainset_wv)\n",
    "    \n",
    "    predictions_test = lrModel.transform(test_data_wv)\n",
    "    predictions_test = predictions_test.withColumn(\"prediction\", predictions_test[\"prediction\"].cast(IntegerType()))\n",
    "    predictions_test = (predictions_test.withColumnRenamed('prediction','prediction%s'%i))\n",
    "    pred_list.append(predictions_test.select('prediction%s'%i).withColumn(\"index\", monotonically_increasing_id()))\n",
    "    print(i)\n",
    "movie_list=predictions_test.select('movie_id').withColumn(\"index\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df=reduce(lambda x,y:x.join(y,['index'],how='full'),[pl.selectExpr('index',f'prediction{i+1}') for i, pl in enumerate(pred_list)])\n",
    "pred_df =pred_df.withColumn('predictions',concat_ws(\" \",*['prediction%d' %i for i in range(1,len(pred_list)+1)])).select('predictions','index')\n",
    "outputfile = pred_df.join(movie_list, on=['index'], how='inner')\n",
    "outputfile.select('movie_id','predictions').toPandas().to_csv('outputpart3.csv',index=False,header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
